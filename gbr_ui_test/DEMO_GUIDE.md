# FUREcast GBR Demo - Presentation Guide

## 🎯 Purpose of This Demo

This skeleton demonstrates the **planned architecture** for FUREcast using a GradientBoostingRegressor approach. It's designed to help your team:

1. **Visualize the user experience** before building the full system
2. **Understand the LLM orchestration pipeline** (router → planner → executor → composer)
3. **See how different modes** (Lite vs Pro) would work
4. **Get hands-on experience** with the interface
5. **Identify improvements** before committing to development

## 🎪 Demo Flow (Recommended)

### Part 1: Introduction (2 minutes)

**Say:**
> "This is a working demo of our proposed FUREcast architecture. It uses simulated data to show how the final application would work. Let me walk you through the key features."

**Show:**
- Open the app in Lite mode
- Point out the educational disclaimer
- Show the sidebar information

---

### Part 2: Lite Mode Demo (3 minutes)

**Say:**
> "Lite mode is for users who want a quick prediction without diving deep into analytics."

**Show:**
1. **Prediction Card**
   - Direction (Up/Down/Neutral)
   - Expected return percentage
   - Confidence score

2. **Feature Importance**
   - Bar chart showing which indicators drove the prediction
   - Top 5 features with importance scores
   - LLM-generated explanation of what these features mean

3. **Price Chart**
   - Historical SPLG prices
   - Moving averages (20-day, 50-day)
   - Interactive Plotly chart

**Click "Refresh Prediction"** to show that it generates a new forecast

**Explain:**
> "In production, the prediction would come from our trained GBR model. Here, we're using OpenAI to simulate realistic predictions based on market patterns."

---

### Part 3: Pro Mode Demo (5 minutes)

**Switch to Pro mode in sidebar**

**Say:**
> "Pro mode adds natural language querying powered by an LLM that orchestrates data tools."

**Show the architecture:**
> "When you ask a question, the system:
> 1. Routes it to classify intent
> 2. Plans which tools to use
> 3. Executes data fetches and calculations
> 4. Composes a natural language answer
> 5. Generates relevant visualizations"

#### Demo Query 1: "Which sectors look stable this quarter?"

**What happens:**
- System classifies as "sector_analysis"
- Plans to compute risk metrics
- Generates sector risk treemap
- LLM explains which sectors are low-volatility

**Point out:**
- The treemap (size = market cap, color = volatility)
- How the answer grounds itself in data
- Educational tone of the response

#### Demo Query 2: "What influenced today's prediction?"

**What happens:**
- System identifies this as "feature_explanation"
- Shows feature importance chart
- LLM explains what RSI, MACD, etc. mean in context

**Point out:**
- Explainability of the model
- Educational value for learning technical indicators

#### Demo Query 3: "Compare Technology vs Utilities performance"

**What happens:**
- System recognizes comparison request
- Generates normalized performance chart
- LLM analyzes relative performance

**Show the "System Plan" expander:**
> "This JSON shows exactly what tools the LLM decided to call. In production, this would trigger real data fetches and calculations."

---

### Part 4: Quick Analytics Tabs (2 minutes)

**Show the three tabs:**

1. **Sector Risk** - Interactive treemap
2. **Price Trends** - Full-year chart
3. **Feature Analysis** - Model explainability

**Say:**
> "These provide quick access to common analytics without typing questions."

---

## 💬 Talking Points for Your Team

### Architecture Benefits

**Point 1: Modularity**
> "Notice how the system is cleanly separated: `simulator.py` handles data, `llm_interface.py` handles AI orchestration, and `app.py` is just UI. This makes it easy to swap simulated functions for real ones."

**Point 2: LLM as Orchestrator**
> "We're not asking the LLM to do math or predictions. It's a router and explainer. The actual calculations come from deterministic functions. This keeps results accurate while adding natural language flexibility."

**Point 3: Tool-Based Safety**
> "The LLM can only call whitelisted tools. It can't execute arbitrary code or make financial decisions. Everything is controlled and logged."

### What's Simulated (and What's Real)

**Simulated:**
- Market data (prices, volumes)
- GBR predictions (generated by LLM mimicking model output)
- Risk calculations (realistic but not from real data)

**Real:**
- LLM routing and planning
- Chart generation
- UI interactions
- Architecture pattern

**Say:**
> "Think of this as a high-fidelity wireframe. The skeleton is real, the data is simulated."

---

## 🤔 Discussion Questions for Your Team

After the demo, ask:

1. **"Does this interface make sense for our target users?"**
   - Too complex? Too simple?
   - Is the Lite/Pro split useful?

2. **"Are we missing any key features?"**
   - What visualizations should we add?
   - What queries should the system handle?

3. **"Is the GBR approach the right choice?"**
   - Pros: Fast, explainable, works with tabular data
   - Cons: May not capture complex patterns like LSTM
   - Should we consider ensemble methods?

4. **"How should we handle the LLM costs?"**
   - Every query in Pro mode calls OpenAI 2-3 times
   - Could we cache common queries?
   - Should Lite mode be the default?

5. **"What's our MVP for the semester?"**
   - Given time constraints, what must we build?
   - What can be stretch goals?

---

## 📊 Feature Comparison: What's in This Demo

| Feature | Demo Status | Notes |
|---------|-------------|-------|
| GBR Prediction Card | ✅ Simulated | Shows direction, return, confidence |
| Feature Importance | ✅ Simulated | Bar chart + explanation |
| LLM Query Interface | ✅ Functional | Real OpenAI calls |
| Intent Classification | ✅ Functional | Routes queries to tools |
| Tool Planning | ✅ Functional | Generates JSON execution plans |
| Answer Composition | ✅ Functional | Natural language synthesis |
| Price Charts | ✅ Simulated data | Real Plotly rendering |
| Sector Risk Treemap | ✅ Simulated data | Real visualization |
| Sector Comparison | ✅ Simulated data | Real charting |
| Lite/Pro Modes | ✅ Functional | Mode switching works |
| Database | ❌ Not implemented | Would need SQLite |
| Real Market APIs | ❌ Not implemented | Would need yfinance/Alpha Vantage |
| Trained GBR Model | ❌ Not implemented | Would need model training pipeline |
| Dividend Calendar | ❌ Not included | Planned for Phase 4 |
| Timeline Embeds | ❌ Not included | Planned for Phase 4 |
| Investment Simulator | ❌ Not included | Planned for Phase 4 |

---

## 🛣️ Roadmap Discussion

Use this demo to discuss:

### Phase Priority

**Option A: Model-First**
1. Train GBR on real SPLG data
2. Build data pipeline
3. Add basic UI
4. Integrate LLM later

**Option B: Architecture-First** (This demo's approach)
1. Build full architecture with simulated data
2. Train model in parallel
3. Swap simulated components for real ones
4. Iterate

**Option C: Hybrid**
1. Start with basic trained model
2. Build Lite mode only
3. Add Pro mode if time permits
4. Polish visualizations

### Resource Allocation

**If you have:**
- **1 ML-focused person** → Focus on GBR training & evaluation
- **1 Backend person** → Build data pipeline & tool layer
- **1 Frontend person** → Polish UI & add visualizations
- **1 Integration person** → Connect LLM & orchestration

### Timeline Checkpoints

**Week 4:** Demo trained GBR model with evaluation metrics
**Week 6:** Working Lite mode with real model
**Week 8:** Data pipeline feeding real prices
**Week 10:** Pro mode with LLM (if scope permits)
**Week 11:** Polish & prepare presentation
**Week 12:** Final demo & submission

---

## 🎓 Educational Value

Highlight to your instructor/team:

**This project demonstrates:**
1. ✅ Machine learning model training & evaluation
2. ✅ API integration & data engineering
3. ✅ LLM orchestration & prompt engineering
4. ✅ Full-stack development (backend + frontend)
5. ✅ UX design for data analytics
6. ✅ Software architecture & modularity
7. ✅ Deployment & production considerations

---

## 🚀 Next Steps After This Demo

1. **Gather feedback** from all team members
2. **Decide on MVP scope** - what MUST be done vs nice-to-have
3. **Assign roles** based on skills and interests
4. **Set up project board** - track tasks and progress
5. **Start parallel work:**
   - Data team: Feature engineering for GBR
   - Model team: Train and evaluate GBR
   - UI team: Refine Streamlit based on feedback
6. **Schedule weekly check-ins** to show progress

---

## 💡 Tips for the Demo

- **Run through it once alone first** to make sure everything works
- **Have your OpenAI API key ready** before starting
- **Keep browser DevTools open** to show it's a real web app
- **Prepare 2-3 interesting queries** to showcase Pro mode
- **Be ready to explain "simulated"** - it's not a limitation, it's a smart demo strategy
- **Emphasize the architecture** over the data

Good luck! 🎉
